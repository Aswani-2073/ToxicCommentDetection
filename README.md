# ğŸ›¡ï¸ Toxic Comment Detection

This project detects **toxic, offensive, or hateful comments** in real-time using **Machine Learning and Deep Learning** models.  
It includes a **Streamlit web application** where users can enter a comment or upload a CSV file to get predictions.

---

## ğŸ“Œ Features
- âœ… **Text Preprocessing**: cleaning, tokenization, TF-IDF features  
- âœ… **Baseline Model**: Logistic Regression with TF-IDF  
- âœ… **Deep Learning Model**: BiLSTM for contextual understanding  
- âœ… **Model Comparison**: Accuracy, Precision, Recall, F1-score  
- âœ… **Streamlit Web App**:
  - Single comment prediction  
  - Bulk prediction via CSV upload  
  - Downloadable results  
  - Charts & insights  

---

## ğŸ“‚ Project Structure
ToxicCommentDetection/
â”‚â”€â”€ app.py # Streamlit app
â”‚â”€â”€ README.md # Project documentation (this file)
â”‚â”€â”€ models/ # Saved models
â”‚ â”œâ”€â”€ logreg_toxicity.joblib
â”‚ â”œâ”€â”€ tfidf_vectorizer.joblib
â”‚ â”œâ”€â”€ bilstm_model.h5
â”‚ â”œâ”€â”€ bilstm_tokenizer.json
â”‚â”€â”€ sample_comments.csv # Example CSV for bulk testing
â”‚â”€â”€ train.csv # Training dataset (not included in repo)


---

## âš¡ Installation & Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/YOUR-USERNAME/ToxicCommentDetection.git
   cd ToxicCommentDetection


(Optional) Create a virtual environment:

python3 -m venv .venv
source .venv/bin/activate


Install the required dependencies:
pip install streamlit transformers torch torchvision torchaudio pandas numpy scikit-learn tensorflow matplotlib


Run the Streamlit app:
streamlit run app.py

ğŸ“Š Model Performance
Model	             Accuracy	    Precision	Recall	F1-Score
Logistic Regression	0.83	    0.79	        0.75	0.77
BiLSTM            	0.87	    0.84	        0.82	0.83
